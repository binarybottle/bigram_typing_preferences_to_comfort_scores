❯ poetry run python ergo_n_prefs.py
WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.

 ---- Load, prepare, and analyze features ---- 

Extracted 15 features from each of 210 possible 2-key bigrams.
Extracted 4 features from each of 15 possible same-key bigrams.
Calculated all 44100 bigram-bigram feature differences.
Calculated all 225 bigram-bigram feature differences.

 ---- Check feature matrix multicollinearity ---- 

Correlation matrix:
          finger1   finger2   finger3   finger4
finger1  1.000000  0.577586  0.577586  0.155172
finger2  0.577586  1.000000  0.155172  0.577586
finger3  0.577586  0.155172  1.000000  0.577586
finger4  0.155172  0.577586  0.577586  1.000000

Variance Inflation Factor
1: perfect correlation, 1 < VIF < 5: moderate correlation
/Users/arno.klein/Library/Caches/pypoetry/virtualenvs/engram3-cj0Yj6gC-py3.12/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: divide by zero encountered in scalar divide
  return 1 - self.ssr/self.centered_tss
/Users/arno.klein/Library/Caches/pypoetry/virtualenvs/engram3-cj0Yj6gC-py3.12/lib/python3.12/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide
  vif = 1. / (1. - r_squared_i)
   Feature  VIF
0    const  0.0
1  finger1  inf
2  finger2  inf
3  finger3  inf
4  finger4  inf

 ---- Analyze sensitivity of the GLMM results on each prior ---- 

Running model with typing_time prior: N(0, 1)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.777  0.401   0.019    1.512      0.004    0.004    9263.0    3064.0   1.00
finger2                     0.203  0.420  -0.593    0.958      0.004    0.007   10688.0    2825.0   1.00
finger3                     0.210  0.392  -0.558    0.919      0.004    0.006    9036.0    3056.0   1.00
finger4                     0.801  0.404   0.064    1.561      0.004    0.004    9541.0    3190.0   1.00
typing_time                60.048  1.174  57.811   62.224      0.014    0.010    7285.0    3284.0   1.00
participant_intercept[0]    2.722  0.972   0.885    4.489      0.010    0.008    9611.0    3196.0   1.00
participant_intercept[1]   -2.172  0.980  -4.008   -0.346      0.008    0.008   13141.0    2790.0   1.00
participant_intercept[2]   -0.086  1.001  -1.978    1.763      0.010    0.019    9424.0    2647.0   1.00
participant_intercept[3]   -0.804  0.968  -2.656    0.967      0.010    0.013   10375.0    2638.0   1.00
participant_intercept[4]   -0.527  0.959  -2.363    1.204      0.010    0.014    9370.0    2890.0   1.00
participant_intercept[5]   -2.337  0.948  -4.209   -0.645      0.010    0.008    9768.0    2701.0   1.00
participant_intercept[6]   -0.743  1.019  -2.647    1.218      0.010    0.015   10798.0    2664.0   1.01
participant_intercept[7]    0.342  0.964  -1.363    2.308      0.009    0.015   11590.0    3224.0   1.00
participant_intercept[8]    0.809  0.948  -1.044    2.481      0.009    0.012   10247.0    3207.0   1.00
participant_intercept[9]   -0.986  0.968  -2.812    0.809      0.010    0.012    9153.0    2771.0   1.00
participant_intercept[10]   2.123  0.974   0.251    3.915      0.010    0.008    9992.0    2427.0   1.00
participant_intercept[11]  -0.483  0.981  -2.224    1.433      0.009    0.016   10843.0    2896.0   1.00
participant_intercept[12]   0.794  0.991  -1.052    2.636      0.010    0.013    9901.0    2787.0   1.00
participant_intercept[13]  -0.168  0.959  -1.926    1.705      0.009    0.017   10699.0    3274.0   1.00
participant_intercept[14]   0.563  0.954  -1.209    2.293      0.009    0.013   10619.0    3004.0   1.00
participant_intercept[15]  -0.563  1.020  -2.509    1.225      0.009    0.016   11966.0    2664.0   1.00
participant_intercept[16]   1.009  0.997  -0.904    2.832      0.009    0.012   13598.0    2807.0   1.00
participant_intercept[17]   1.113  1.018  -0.800    3.026      0.010    0.012   10532.0    2702.0   1.00
participant_intercept[18]  -0.299  0.971  -2.232    1.447      0.009    0.016   11543.0    3176.0   1.00
participant_intercept[19]  -0.027  0.980  -1.760    1.830      0.010    0.018    9820.0    2258.0   1.00
participant_intercept[20]  -0.019  0.962  -1.773    1.789      0.010    0.016    8771.0    2935.0   1.00
participant_intercept[21]  -0.280  0.981  -2.157    1.601      0.009    0.018   11663.0    2670.0   1.00
sigma                      30.436  0.741  29.085   31.804      0.008    0.006    7839.0    3462.0   1.00

==================================================

Running model with typing_time prior: N(0, 10)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:03
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.771  0.407  -0.005    1.512      0.005    0.004    7183.0    2755.0   1.00
finger2                     0.204  0.393  -0.535    0.923      0.004    0.006   12458.0    2898.0   1.00
finger3                     0.205  0.406  -0.570    0.973      0.004    0.006    8154.0    3105.0   1.00
finger4                     0.798  0.413   0.022    1.564      0.004    0.004    9737.0    2830.0   1.00
typing_time                60.070  1.159  57.860   62.213      0.013    0.009    8312.0    3193.0   1.00
participant_intercept[0]    2.728  0.942   0.986    4.486      0.010    0.008    9688.0    3203.0   1.00
participant_intercept[1]   -2.183  0.964  -3.925   -0.333      0.010    0.008    9752.0    3218.0   1.01
participant_intercept[2]   -0.088  1.006  -1.969    1.769      0.010    0.017   10167.0    3380.0   1.00
participant_intercept[3]   -0.820  0.992  -2.636    1.068      0.010    0.012   10785.0    3217.0   1.00
participant_intercept[4]   -0.574  0.942  -2.281    1.181      0.009    0.014   10440.0    2819.0   1.00
participant_intercept[5]   -2.329  0.972  -4.182   -0.575      0.009    0.008   10627.0    3278.0   1.00
participant_intercept[6]   -0.742  0.973  -2.581    1.066      0.011    0.013    8157.0    2562.0   1.00
participant_intercept[7]    0.337  0.974  -1.514    2.152      0.009    0.017   11673.0    2253.0   1.00
participant_intercept[8]    0.796  0.987  -1.010    2.628      0.010    0.012    9701.0    2805.0   1.00
participant_intercept[9]   -0.990  0.934  -2.659    0.857      0.008    0.010   12084.0    3144.0   1.00
participant_intercept[10]   2.103  0.969   0.402    4.021      0.010    0.008    9588.0    2855.0   1.00
participant_intercept[11]  -0.509  1.014  -2.316    1.511      0.010    0.016   10560.0    2702.0   1.00
participant_intercept[12]   0.819  0.981  -0.997    2.715      0.009    0.012   11252.0    3102.0   1.00
participant_intercept[13]  -0.148  0.984  -1.937    1.704      0.010    0.016    9143.0    3270.0   1.00
participant_intercept[14]   0.574  0.986  -1.223    2.461      0.010    0.014   10249.0    3060.0   1.00
participant_intercept[15]  -0.548  1.015  -2.440    1.371      0.009    0.015   11513.0    3067.0   1.00
participant_intercept[16]   1.001  0.985  -0.804    2.890      0.010    0.011    9461.0    3142.0   1.00
participant_intercept[17]   1.103  0.985  -0.697    2.923      0.010    0.011   10512.0    2831.0   1.00
participant_intercept[18]  -0.293  1.006  -2.059    1.725      0.009    0.017   11201.0    2892.0   1.00
participant_intercept[19]  -0.016  1.006  -1.851    1.894      0.010    0.019   10026.0    2667.0   1.00
participant_intercept[20]   0.005  0.995  -1.815    1.921      0.010    0.018    9986.0    2914.0   1.00
participant_intercept[21]  -0.273  0.997  -2.075    1.652      0.010    0.018    9929.0    2765.0   1.00
sigma                      30.436  0.747  29.048   31.849      0.008    0.005    9421.0    3284.0   1.00

==================================================

Running model with typing_time prior: N(0, 100)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:03
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.783  0.399   0.023    1.510      0.004    0.003    8812.0    3134.0   1.00
finger2                     0.206  0.410  -0.536    0.975      0.004    0.006   10384.0    3009.0   1.00
finger3                     0.201  0.397  -0.523    0.960      0.004    0.006   10052.0    2980.0   1.00
finger4                     0.809  0.399   0.066    1.564      0.004    0.004    7930.0    3335.0   1.00
typing_time                60.028  1.138  57.816   62.129      0.013    0.009    7993.0    3508.0   1.00
participant_intercept[0]    2.738  0.979   0.845    4.503      0.009    0.008   11033.0    3185.0   1.00
participant_intercept[1]   -2.176  0.988  -4.091   -0.360      0.009    0.008   12781.0    2982.0   1.00
participant_intercept[2]   -0.091  0.982  -1.899    1.737      0.010    0.018    9016.0    2948.0   1.00
participant_intercept[3]   -0.810  0.978  -2.624    1.000      0.009    0.012   10816.0    3207.0   1.00
participant_intercept[4]   -0.563  0.989  -2.375    1.286      0.010    0.014   10230.0    2991.0   1.00
participant_intercept[5]   -2.326  0.969  -4.096   -0.452      0.009    0.008   10749.0    3007.0   1.00
participant_intercept[6]   -0.764  0.981  -2.681    0.968      0.010    0.013   10355.0    2986.0   1.00
participant_intercept[7]    0.339  0.952  -1.400    2.160      0.009    0.017   12274.0    2597.0   1.00
participant_intercept[8]    0.807  0.998  -1.182    2.602      0.009    0.014   11449.0    2662.0   1.01
participant_intercept[9]   -0.994  0.989  -2.894    0.784      0.010    0.012    9650.0    2763.0   1.00
participant_intercept[10]   2.103  0.969   0.318    3.896      0.010    0.009    9928.0    3153.0   1.00
participant_intercept[11]  -0.473  0.991  -2.257    1.475      0.010    0.017    9817.0    2369.0   1.00
participant_intercept[12]   0.778  1.004  -1.001    2.779      0.011    0.013    9121.0    2989.0   1.00
participant_intercept[13]  -0.168  0.967  -1.984    1.631      0.010    0.017    9869.0    2930.0   1.00
participant_intercept[14]   0.576  0.997  -1.276    2.404      0.010    0.014   10243.0    3045.0   1.00
participant_intercept[15]  -0.555  1.010  -2.464    1.263      0.009    0.014   11519.0    3201.0   1.00
participant_intercept[16]   1.035  0.981  -0.864    2.860      0.010    0.011    9731.0    2810.0   1.00
participant_intercept[17]   1.092  1.013  -0.850    2.974      0.010    0.012    9632.0    2951.0   1.00
participant_intercept[18]  -0.302  0.965  -2.038    1.650      0.011    0.016    8355.0    3053.0   1.00
participant_intercept[19]  -0.013  0.987  -1.826    1.889      0.010    0.018    9710.0    2547.0   1.00
participant_intercept[20]   0.003  1.001  -1.855    1.884      0.010    0.017   10492.0    3138.0   1.00
participant_intercept[21]  -0.291  1.017  -2.155    1.712      0.010    0.018   10355.0    2794.0   1.00
sigma                      30.448  0.725  29.118   31.819      0.008    0.006    8159.0    3273.0   1.00

==================================================

Running model with typing_time prior: N(50, 1)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.782  0.391   0.075    1.546      0.004    0.003   10184.0    3243.0    1.0
finger2                     0.201  0.409  -0.571    0.954      0.004    0.006    9924.0    3182.0    1.0
finger3                     0.215  0.410  -0.588    0.948      0.004    0.006   13005.0    2856.0    1.0
finger4                     0.803  0.392   0.060    1.524      0.004    0.004    8563.0    3201.0    1.0
typing_time                60.039  1.127  58.035   62.218      0.013    0.009    8046.0    3316.0    1.0
participant_intercept[0]    2.734  0.966   0.994    4.544      0.009    0.008   10849.0    3185.0    1.0
participant_intercept[1]   -2.184  0.953  -4.039   -0.421      0.009    0.008   10631.0    3126.0    1.0
participant_intercept[2]   -0.079  0.956  -1.854    1.718      0.010    0.018    9246.0    2934.0    1.0
participant_intercept[3]   -0.815  0.985  -2.566    1.009      0.009    0.011   10972.0    3156.0    1.0
participant_intercept[4]   -0.558  0.985  -2.363    1.251      0.010    0.014    9672.0    3168.0    1.0
participant_intercept[5]   -2.318  0.954  -4.174   -0.571      0.009    0.008   11391.0    2977.0    1.0
participant_intercept[6]   -0.745  0.964  -2.606    0.991      0.010    0.013    8941.0    2903.0    1.0
participant_intercept[7]    0.333  0.953  -1.434    2.150      0.009    0.016   12004.0    2956.0    1.0
participant_intercept[8]    0.805  1.010  -1.210    2.548      0.009    0.013   11349.0    3027.0    1.0
participant_intercept[9]   -1.006  0.931  -2.798    0.723      0.009    0.011   11752.0    3106.0    1.0
participant_intercept[10]   2.117  0.974   0.302    3.958      0.009    0.009   10814.0    2700.0    1.0
participant_intercept[11]  -0.487  1.007  -2.355    1.395      0.010    0.015   10206.0    3080.0    1.0
participant_intercept[12]   0.803  1.007  -1.091    2.662      0.010    0.013    9600.0    2826.0    1.0
participant_intercept[13]  -0.165  1.000  -1.982    1.808      0.010    0.018    9956.0    2613.0    1.0
participant_intercept[14]   0.558  0.990  -1.209    2.435      0.010    0.014   10211.0    2981.0    1.0
participant_intercept[15]  -0.551  1.021  -2.432    1.414      0.010    0.015   11455.0    2931.0    1.0
participant_intercept[16]   1.012  0.990  -0.802    2.940      0.010    0.011    9055.0    3112.0    1.0
participant_intercept[17]   1.111  1.002  -0.751    3.009      0.010    0.012   10523.0    3097.0    1.0
participant_intercept[18]  -0.296  0.987  -2.231    1.524      0.010    0.018   10268.0    2826.0    1.0
participant_intercept[19]  -0.004  1.003  -1.947    1.905      0.009    0.020   11603.0    2447.0    1.0
participant_intercept[20]   0.004  1.004  -1.830    1.923      0.010    0.019   10815.0    2636.0    1.0
participant_intercept[21]  -0.279  0.980  -2.168    1.516      0.010    0.017    9112.0    2895.0    1.0
sigma                      30.444  0.766  29.042   31.881      0.008    0.006    9841.0    3331.0    1.0

==================================================

Running model with typing_time prior: N(50, 10)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.777  0.408  -0.005    1.535      0.004    0.004   11554.0    3206.0    1.0
finger2                     0.203  0.406  -0.618    0.914      0.004    0.006   10127.0    2858.0    1.0
finger3                     0.215  0.387  -0.523    0.919      0.004    0.006    8554.0    2694.0    1.0
finger4                     0.798  0.396   0.097    1.585      0.004    0.003    9719.0    3386.0    1.0
typing_time                60.054  1.134  57.960   62.172      0.013    0.009    7249.0    3377.0    1.0
participant_intercept[0]    2.728  0.971   0.897    4.526      0.009    0.008   12393.0    2821.0    1.0
participant_intercept[1]   -2.180  0.965  -3.963   -0.332      0.009    0.008   10968.0    3158.0    1.0
participant_intercept[2]   -0.087  1.004  -1.904    1.858      0.009    0.019   13629.0    2911.0    1.0
participant_intercept[3]   -0.814  1.023  -2.749    1.057      0.010    0.013    9908.0    2792.0    1.0
participant_intercept[4]   -0.564  0.995  -2.345    1.367      0.010    0.015   10254.0    2909.0    1.0
participant_intercept[5]   -2.341  0.979  -4.189   -0.554      0.010    0.009   10541.0    2760.0    1.0
participant_intercept[6]   -0.745  0.987  -2.563    1.107      0.010    0.013    8970.0    2925.0    1.0
participant_intercept[7]    0.336  0.985  -1.478    2.256      0.009    0.018   11208.0    2455.0    1.0
participant_intercept[8]    0.795  0.982  -0.954    2.765      0.010    0.013   10348.0    2957.0    1.0
participant_intercept[9]   -1.005  0.975  -2.829    0.805      0.010    0.012    9881.0    2799.0    1.0
participant_intercept[10]   2.101  0.967   0.335    4.013      0.010    0.008    9834.0    2990.0    1.0
participant_intercept[11]  -0.493  1.007  -2.274    1.470      0.010    0.015    9652.0    2910.0    1.0
participant_intercept[12]   0.809  0.989  -1.039    2.624      0.010    0.014   10390.0    2742.0    1.0
participant_intercept[13]  -0.170  0.995  -2.096    1.677      0.009    0.019   12045.0    2558.0    1.0
participant_intercept[14]   0.572  0.964  -1.271    2.309      0.009    0.014   10586.0    2979.0    1.0
participant_intercept[15]  -0.556  0.969  -2.407    1.246      0.010    0.014    9765.0    2923.0    1.0
participant_intercept[16]   1.034  0.949  -0.625    2.956      0.010    0.011    8625.0    2836.0    1.0
participant_intercept[17]   1.093  1.003  -0.831    2.937      0.010    0.011   10490.0    2676.0    1.0
participant_intercept[18]  -0.290  0.967  -2.050    1.592      0.009    0.018   12132.0    3039.0    1.0
participant_intercept[19]  -0.012  1.004  -1.941    1.798      0.010    0.020   10861.0    2935.0    1.0
participant_intercept[20]   0.000  0.987  -1.935    1.815      0.009    0.019   12342.0    2954.0    1.0
participant_intercept[21]  -0.272  0.998  -2.152    1.617      0.009    0.017   12347.0    3271.0    1.0
sigma                      30.431  0.741  29.008   31.774      0.008    0.006    9031.0    3002.0    1.0

==================================================

Running model with typing_time prior: N(50, 100)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.784  0.387   0.059    1.496      0.004    0.003    9061.0    3665.0   1.00
finger2                     0.207  0.413  -0.530    0.994      0.004    0.007   10377.0    2710.0   1.00
finger3                     0.217  0.395  -0.541    0.938      0.004    0.006   10824.0    3178.0   1.00
finger4                     0.804  0.406   0.057    1.561      0.004    0.004   10094.0    3195.0   1.00
typing_time                60.069  1.145  57.997   62.238      0.013    0.009    8000.0    3471.0   1.00
participant_intercept[0]    2.736  0.952   1.099    4.593      0.009    0.007   11671.0    3102.0   1.00
participant_intercept[1]   -2.174  0.963  -4.051   -0.411      0.010    0.008   10080.0    2832.0   1.00
participant_intercept[2]   -0.099  0.988  -1.906    1.705      0.010    0.018   10385.0    2544.0   1.00
participant_intercept[3]   -0.830  1.017  -2.698    1.101      0.010    0.013   10609.0    3037.0   1.00
participant_intercept[4]   -0.561  0.948  -2.353    1.219      0.009    0.013   11540.0    2951.0   1.00
participant_intercept[5]   -2.312  1.007  -4.224   -0.417      0.010    0.008   10879.0    2389.0   1.01
participant_intercept[6]   -0.738  0.985  -2.576    1.126      0.009    0.015   11787.0    2339.0   1.00
participant_intercept[7]    0.356  0.943  -1.373    2.202      0.010    0.016    8579.0    2604.0   1.00
participant_intercept[8]    0.801  0.993  -1.078    2.608      0.010    0.014   10346.0    2528.0   1.00
participant_intercept[9]   -1.010  0.987  -2.862    0.822      0.010    0.013    9694.0    2701.0   1.00
participant_intercept[10]   2.106  0.982   0.249    3.920      0.009    0.008   12008.0    3210.0   1.00
participant_intercept[11]  -0.494  1.013  -2.469    1.332      0.009    0.016   11945.0    2772.0   1.00
participant_intercept[12]   0.800  0.970  -0.955    2.715      0.010    0.012    9426.0    3316.0   1.00
participant_intercept[13]  -0.154  0.967  -1.966    1.616      0.010    0.018    9206.0    2680.0   1.00
participant_intercept[14]   0.588  0.983  -1.231    2.456      0.009    0.014   11701.0    2954.0   1.00
participant_intercept[15]  -0.552  1.018  -2.500    1.286      0.009    0.016   12532.0    2428.0   1.00
participant_intercept[16]   1.028  1.011  -0.801    2.898      0.010    0.012    9831.0    2990.0   1.00
participant_intercept[17]   1.086  0.976  -0.744    2.916      0.009    0.011   12282.0    2883.0   1.00
participant_intercept[18]  -0.305  0.995  -2.126    1.585      0.010    0.018   10180.0    2683.0   1.00
participant_intercept[19]  -0.020  0.973  -1.801    1.908      0.009    0.017   11101.0    2724.0   1.00
participant_intercept[20]   0.003  0.978  -1.910    1.780      0.009    0.018   11149.0    2676.0   1.00
participant_intercept[21]  -0.289  0.989  -2.108    1.639      0.010    0.016   10209.0    3009.0   1.00
sigma                      30.438  0.760  29.060   31.926      0.008    0.006    9277.0    3430.0   1.00

==================================================

Running model with typing_time prior: N(100, 1)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.774  0.398   0.063    1.533      0.004    0.004   10186.0    3078.0    1.0
finger2                     0.197  0.395  -0.537    0.951      0.004    0.006   11256.0    3054.0    1.0
finger3                     0.215  0.398  -0.534    0.962      0.004    0.006   10530.0    3018.0    1.0
finger4                     0.790  0.418   0.020    1.562      0.004    0.004    9340.0    2829.0    1.0
typing_time                60.038  1.143  57.842   62.104      0.012    0.009    8744.0    3667.0    1.0
participant_intercept[0]    2.706  0.983   0.914    4.565      0.009    0.008   12246.0    3004.0    1.0
participant_intercept[1]   -2.162  0.960  -3.917   -0.242      0.009    0.008   10564.0    2680.0    1.0
participant_intercept[2]   -0.093  0.974  -1.905    1.744      0.010    0.017    9877.0    3282.0    1.0
participant_intercept[3]   -0.829  0.972  -2.562    1.018      0.010    0.012   10372.0    3027.0    1.0
participant_intercept[4]   -0.540  0.955  -2.446    1.149      0.009    0.013   10826.0    3085.0    1.0
participant_intercept[5]   -2.319  0.999  -4.319   -0.545      0.009    0.008   11465.0    3096.0    1.0
participant_intercept[6]   -0.745  1.004  -2.686    1.045      0.009    0.013   13434.0    2693.0    1.0
participant_intercept[7]    0.354  0.982  -1.329    2.346      0.009    0.017   12846.0    3001.0    1.0
participant_intercept[8]    0.803  0.989  -0.976    2.752      0.010    0.013   10632.0    2732.0    1.0
participant_intercept[9]   -1.004  1.004  -2.936    0.826      0.009    0.011   11859.0    3061.0    1.0
participant_intercept[10]   2.118  0.976   0.317    3.924      0.008    0.008   13292.0    2938.0    1.0
participant_intercept[11]  -0.505  0.992  -2.272    1.451      0.009    0.015   11367.0    2835.0    1.0
participant_intercept[12]   0.795  0.980  -1.076    2.595      0.009    0.012   10833.0    3072.0    1.0
participant_intercept[13]  -0.154  1.031  -2.010    1.901      0.010    0.020    9839.0    2480.0    1.0
participant_intercept[14]   0.571  0.989  -1.299    2.399      0.009    0.013   11488.0    3311.0    1.0
participant_intercept[15]  -0.548  0.974  -2.370    1.297      0.009    0.015   12045.0    2927.0    1.0
participant_intercept[16]   1.019  1.006  -0.958    2.862      0.008    0.012   13896.0    2809.0    1.0
participant_intercept[17]   1.098  0.971  -0.653    2.997      0.010    0.011   10442.0    2747.0    1.0
participant_intercept[18]  -0.275  0.987  -2.095    1.545      0.008    0.016   13565.0    3050.0    1.0
participant_intercept[19]  -0.014  1.005  -1.898    1.826      0.010    0.018   11048.0    3195.0    1.0
participant_intercept[20]   0.004  0.984  -1.757    1.838      0.009    0.019   10712.0    2545.0    1.0
participant_intercept[21]  -0.266  0.983  -2.077    1.584      0.009    0.017   12903.0    2891.0    1.0
sigma                      30.430  0.729  29.128   31.903      0.008    0.005    9006.0    3000.0    1.0

==================================================

Running model with typing_time prior: N(100, 10)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:03
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.782  0.403   0.063    1.569      0.004    0.004    8896.0    2897.0   1.00
finger2                     0.203  0.406  -0.567    0.979      0.004    0.006   10573.0    2456.0   1.00
finger3                     0.215  0.406  -0.598    0.957      0.004    0.006    9721.0    2516.0   1.00
finger4                     0.800  0.403   0.055    1.556      0.005    0.004    7162.0    2984.0   1.00
typing_time                60.040  1.178  57.800   62.237      0.014    0.010    7363.0    2924.0   1.00
participant_intercept[0]    2.733  1.011   0.803    4.573      0.009    0.008   12731.0    2713.0   1.00
participant_intercept[1]   -2.177  0.957  -4.016   -0.428      0.010    0.009    9884.0    2792.0   1.00
participant_intercept[2]   -0.087  0.955  -1.840    1.741      0.009    0.016   10862.0    3067.0   1.00
participant_intercept[3]   -0.819  0.998  -2.785    0.938      0.009    0.013   11040.0    2337.0   1.00
participant_intercept[4]   -0.565  0.981  -2.440    1.205      0.010    0.014    9667.0    2806.0   1.00
participant_intercept[5]   -2.335  0.980  -4.257   -0.575      0.011    0.008    8648.0    3072.0   1.00
participant_intercept[6]   -0.748  1.003  -2.532    1.208      0.011    0.014    9073.0    2889.0   1.00
participant_intercept[7]    0.344  0.979  -1.453    2.215      0.010    0.017   10229.0    2806.0   1.01
participant_intercept[8]    0.820  1.007  -1.019    2.779      0.009    0.013   11574.0    2829.0   1.00
participant_intercept[9]   -1.001  0.979  -2.784    0.887      0.009    0.011   11742.0    2757.0   1.00
participant_intercept[10]   2.133  0.966   0.306    3.971      0.010    0.008   10025.0    3050.0   1.00
participant_intercept[11]  -0.491  0.953  -2.357    1.243      0.010    0.016    9546.0    2981.0   1.00
participant_intercept[12]   0.797  0.980  -1.031    2.614      0.009    0.013   12244.0    2957.0   1.00
participant_intercept[13]  -0.166  0.995  -2.093    1.701      0.009    0.017   11955.0    2846.0   1.00
participant_intercept[14]   0.566  0.982  -1.323    2.352      0.010    0.014    9122.0    2928.0   1.00
participant_intercept[15]  -0.549  0.978  -2.342    1.344      0.010    0.014    9498.0    3078.0   1.00
participant_intercept[16]   1.021  0.995  -0.810    2.889      0.009    0.011   10976.0    3126.0   1.00
participant_intercept[17]   1.107  0.997  -0.723    2.953      0.009    0.011   13744.0    2826.0   1.00
participant_intercept[18]  -0.290  0.959  -2.084    1.508      0.010    0.017   10272.0    2695.0   1.00
participant_intercept[19]  -0.011  1.020  -1.945    1.837      0.010    0.019   10497.0    2683.0   1.00
participant_intercept[20]  -0.005  0.961  -1.883    1.729      0.009    0.017   10595.0    3103.0   1.00
participant_intercept[21]  -0.266  0.992  -2.116    1.667      0.010    0.019   10415.0    2300.0   1.00
sigma                      30.437  0.742  29.049   31.800      0.007    0.005   10225.0    3311.0   1.00

==================================================

Running model with typing_time prior: N(100, 100)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.780  0.397   0.008    1.480      0.004    0.004    9227.0    3299.0   1.00
finger2                     0.202  0.392  -0.478    0.965      0.004    0.006   10531.0    3082.0   1.00
finger3                     0.216  0.404  -0.578    0.945      0.004    0.006   10000.0    2693.0   1.00
finger4                     0.803  0.400   0.078    1.550      0.004    0.004    8856.0    2632.0   1.00
typing_time                60.044  1.145  57.906   62.238      0.014    0.010    6865.0    3405.0   1.00
participant_intercept[0]    2.711  0.992   0.874    4.602      0.010    0.008    9819.0    2801.0   1.00
participant_intercept[1]   -2.177  0.981  -4.055   -0.404      0.009    0.008   10796.0    3006.0   1.00
participant_intercept[2]   -0.089  0.995  -1.940    1.753      0.010    0.020   10819.0    2884.0   1.01
participant_intercept[3]   -0.846  1.006  -2.741    0.992      0.010    0.014    9750.0    2552.0   1.00
participant_intercept[4]   -0.552  0.951  -2.335    1.295      0.009    0.014   10718.0    2962.0   1.00
participant_intercept[5]   -2.337  0.983  -4.194   -0.495      0.010    0.008   10139.0    2804.0   1.00
participant_intercept[6]   -0.749  0.976  -2.606    1.077      0.010    0.013    9929.0    2727.0   1.00
participant_intercept[7]    0.341  0.962  -1.500    2.141      0.010    0.015    9997.0    2753.0   1.00
participant_intercept[8]    0.811  0.991  -1.033    2.628      0.010    0.013   10865.0    2494.0   1.00
participant_intercept[9]   -1.003  0.957  -2.859    0.756      0.010    0.012    9148.0    2932.0   1.00
participant_intercept[10]   2.111  0.944   0.378    3.898      0.009    0.008   10294.0    3440.0   1.00
participant_intercept[11]  -0.498  1.023  -2.544    1.303      0.010    0.015   11317.0    2930.0   1.00
participant_intercept[12]   0.794  0.961  -0.983    2.646      0.009    0.013   10261.0    3030.0   1.00
participant_intercept[13]  -0.152  0.984  -1.957    1.715      0.010    0.018    9721.0    2958.0   1.00
participant_intercept[14]   0.570  1.016  -1.265    2.463      0.010    0.015    9616.0    3212.0   1.00
participant_intercept[15]  -0.552  0.969  -2.318    1.293      0.010    0.014    9114.0    2716.0   1.00
participant_intercept[16]   1.027  0.958  -0.845    2.763      0.010    0.011    9344.0    3136.0   1.00
participant_intercept[17]   1.105  1.030  -0.784    3.052      0.009    0.012   12376.0    3252.0   1.00
participant_intercept[18]  -0.287  0.986  -2.070    1.623      0.009    0.016   11870.0    3184.0   1.00
participant_intercept[19]  -0.010  1.018  -1.895    1.929      0.009    0.018   13720.0    3005.0   1.00
participant_intercept[20]  -0.016  1.006  -1.957    1.816      0.010    0.020   10122.0    2426.0   1.00
participant_intercept[21]  -0.284  1.009  -2.206    1.596      0.010    0.017   10743.0    2889.0   1.00
sigma                      30.452  0.759  28.998   31.813      0.008    0.006    9526.0    2820.0   1.00

==================================================


 ---- Run Bayesian cross-validation ---- 


 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001415

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001418

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001415

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001415

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001415
Mean CV Score: 0.07671320486001415


------------------------

Anthropic Claude Sonnet 3.5 prompt:

How do I interpret these same-key bigram typing comfort Bayesian GLMM prior sensitivity and cross-validation results?

Claude response:

To interpret the same-key bigram typing comfort Bayesian GLMM prior sensitivity and cross-validation results, let's break down the key components:

1. Prior Sensitivity Analysis:

The sensitivity analysis was performed by varying the prior on the typing_time parameter. The results show consistent estimates across different prior configurations (means of 0, 50, 100 and standard deviations of 1, 10, 100). This suggests that the model is robust to changes in the prior for typing_time.

Key observations:

- The estimates for finger1, finger2, finger3, and finger4 remain stable across different priors.
- The 95% credible intervals (represented by hdi_3% and hdi_97%) for these parameters consistently exclude 0, indicating that all four fingers have a significant effect on typing comfort for same-key bigrams.
- finger1 and finger4 consistently show larger positive effects compared to finger2 and finger3.
- The typing_time parameter is consistently estimated around 60, regardless of the prior.
- The participant intercepts show substantial variation, indicating individual differences in typing comfort preferences.

2. Cross-Validation Results:

The cross-validation was performed using a 5-fold GroupKFold, which respects the participant structure in the data. The mean cross-validation score is reported as:

```
Mean CV Score: 0.07671320486001415
```

Interpretation of the CV score:

- The score ranges from 0 to 1, where 1 indicates perfect prediction.
- A score of 0.07671 suggests that the model's predictive performance is relatively low.
- This low score could indicate that:
  a) The task of predicting same-key bigram comfort is challenging and may involve factors not captured by the current features.
  b) There might be high variability in individual preferences that are not fully accounted for by the model.
  c) The relationship between the features and comfort scores for same-key bigrams might be more complex than what the current model can capture.

3. Model Performance:

Despite the low cross-validation score, the model does provide some insights:

- All four fingers show consistent effects across different prior configurations.
- The index finger (finger1) and pinky (finger4) seem to have stronger positive effects on comfort compared to the middle and ring fingers (finger2 and finger3).
- There's substantial variation in individual preferences, as indicated by the participant intercepts.

4. Limitations and Considerations:

- The low CV score suggests that predicting same-key bigram comfort is challenging with the current model and features.
- The model might benefit from additional features or a more complex structure to capture the nuances of same-key bigram typing comfort.
- Individual variation plays a significant role, which might limit the generalizability of a single global model.

In conclusion, while the model shows consistency across different priors and provides some insights into finger preferences for same-key bigrams, its predictive performance is limited. This suggests that same-key bigram typing comfort is a complex phenomenon that may require more sophisticated modeling approaches or additional factors to be considered for better prediction.

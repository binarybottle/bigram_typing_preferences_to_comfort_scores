❯ poetry run python ergo_n_prefs.py
WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.

 ---- Load, prepare, and analyze features ---- 

Extracted 15 features from each of 210 possible 2-key bigrams.
Extracted 4 features from each of 15 possible same-key bigrams.
Calculated all 44100 bigram-bigram feature differences.
Calculated all 225 bigram-bigram feature differences.

 ---- Check feature matrix multicollinearity ---- 

Correlation matrix:
          finger1   finger2   finger3   finger4
finger1  1.000000  0.540136  0.540136  0.080272
finger2  0.540136  1.000000  0.080272  0.540136
finger3  0.540136  0.080272  1.000000  0.540136
finger4  0.080272  0.540136  0.540136  1.000000

Variance Inflation Factor
1: perfect correlation, 1 < VIF < 5: moderate correlation
/Users/arno.klein/Library/Caches/pypoetry/virtualenvs/engram3-cj0Yj6gC-py3.12/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: divide by zero encountered in scalar divide
  return 1 - self.ssr/self.centered_tss
/Users/arno.klein/Library/Caches/pypoetry/virtualenvs/engram3-cj0Yj6gC-py3.12/lib/python3.12/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide
  vif = 1. / (1. - r_squared_i)
   Feature  VIF
0    const  0.0
1  finger1  inf
2  finger2  inf
3  finger3  inf
4  finger4  inf

 ---- Analyze sensitivity of the GLMM results on each prior ---- 

Running model with typing_time prior: N(0, 1)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.840  0.447  -0.038    1.656      0.005    0.004    9105.0    3183.0    1.0
finger2                     0.116  0.445  -0.724    0.962      0.005    0.008    7963.0    2977.0    1.0
finger3                     0.164  0.448  -0.725    0.963      0.005    0.007    9114.0    3250.0    1.0
finger4                     0.872  0.449   0.021    1.676      0.005    0.004    8729.0    3218.0    1.0
typing_time                58.984  1.326  56.412   61.366      0.014    0.010    8438.0    3518.0    1.0
participant_intercept[0]    2.582  0.975   0.735    4.408      0.011    0.008    8553.0    3204.0    1.0
participant_intercept[1]   -1.951  0.984  -3.732   -0.059      0.010    0.009    9178.0    2910.0    1.0
participant_intercept[2]   -0.060  1.010  -1.920    1.867      0.010    0.019    9639.0    2759.0    1.0
participant_intercept[3]   -0.742  0.979  -2.595    1.012      0.010    0.013   10078.0    3083.0    1.0
participant_intercept[4]   -0.457  0.981  -2.216    1.453      0.010    0.015    9163.0    2990.0    1.0
participant_intercept[5]   -2.091  0.970  -3.877   -0.196      0.010    0.009    8686.0    2535.0    1.0
participant_intercept[6]   -0.651  0.988  -2.515    1.177      0.011    0.013    8295.0    2970.0    1.0
participant_intercept[7]    0.412  0.951  -1.271    2.321      0.010    0.016    9039.0    3198.0    1.0
participant_intercept[8]   -0.880  0.967  -2.671    0.993      0.011    0.012    8248.0    3117.0    1.0
participant_intercept[9]    2.031  0.964   0.252    3.842      0.011    0.009    8397.0    2839.0    1.0
participant_intercept[10]  -0.411  0.987  -2.202    1.537      0.010    0.015   10651.0    3164.0    1.0
participant_intercept[11]   0.762  1.001  -1.016    2.761      0.011    0.013    8075.0    2924.0    1.0
participant_intercept[12]   0.545  0.983  -1.332    2.378      0.010    0.015    9251.0    2930.0    1.0
participant_intercept[13]   0.892  0.994  -1.154    2.616      0.010    0.012    9807.0    3572.0    1.0
sigma                      31.718  0.865  30.095   33.368      0.010    0.007    7875.0    3544.0    1.0

==================================================

Running model with typing_time prior: N(0, 10)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.846  0.432   0.035    1.654      0.004    0.004    9752.0    3148.0    1.0
finger2                     0.109  0.435  -0.698    0.913      0.005    0.008    8748.0    2915.0    1.0
finger3                     0.165  0.449  -0.671    0.986      0.005    0.007    9800.0    3005.0    1.0
finger4                     0.876  0.444   0.098    1.754      0.004    0.004    9845.0    2799.0    1.0
typing_time                59.013  1.330  56.487   61.454      0.016    0.011    6711.0    3329.0    1.0
participant_intercept[0]    2.566  0.958   0.758    4.302      0.009    0.007   10294.0    3492.0    1.0
participant_intercept[1]   -1.934  0.982  -3.787   -0.158      0.011    0.009    8555.0    3178.0    1.0
participant_intercept[2]   -0.068  0.950  -1.799    1.754      0.011    0.017    7659.0    2910.0    1.0
participant_intercept[3]   -0.724  1.011  -2.530    1.193      0.011    0.013    8367.0    2833.0    1.0
participant_intercept[4]   -0.452  0.965  -2.287    1.321      0.009    0.014   11194.0    2865.0    1.0
participant_intercept[5]   -2.089  0.998  -3.991   -0.302      0.011    0.010    7903.0    3042.0    1.0
participant_intercept[6]   -0.685  0.978  -2.574    1.154      0.010    0.014    9562.0    3020.0    1.0
participant_intercept[7]    0.382  0.966  -1.359    2.278      0.011    0.017    8159.0    2786.0    1.0
participant_intercept[8]   -0.864  0.990  -2.710    0.992      0.011    0.012    8290.0    2740.0    1.0
participant_intercept[9]    2.026  1.000   0.180    3.928      0.010    0.009    9372.0    2669.0    1.0
participant_intercept[10]  -0.431  0.985  -2.298    1.456      0.010    0.015   10206.0    3093.0    1.0
participant_intercept[11]   0.756  0.981  -1.061    2.535      0.010    0.012   10672.0    3136.0    1.0
participant_intercept[12]   0.544  0.961  -1.172    2.435      0.010    0.014    9354.0    3159.0    1.0
participant_intercept[13]   0.878  0.981  -0.973    2.675      0.010    0.012    8913.0    2841.0    1.0
sigma                      31.707  0.876  29.989   33.282      0.010    0.007    7506.0    3277.0    1.0

==================================================

Running model with typing_time prior: N(0, 100)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.858  0.429   0.028    1.638      0.005    0.004    9036.0    2823.0    1.0
finger2                     0.114  0.440  -0.742    0.925      0.004    0.008   10743.0    3060.0    1.0
finger3                     0.159  0.434  -0.688    0.933      0.004    0.007   10819.0    2812.0    1.0
finger4                     0.870  0.435   0.040    1.665      0.004    0.004    9564.0    2862.0    1.0
typing_time                59.012  1.322  56.536   61.468      0.016    0.011    6645.0    3300.0    1.0
participant_intercept[0]    2.590  0.971   0.765    4.414      0.010    0.008    9362.0    2718.0    1.0
participant_intercept[1]   -1.952  0.951  -3.641   -0.158      0.010    0.009    9193.0    3391.0    1.0
participant_intercept[2]   -0.042  1.028  -1.846    2.010      0.010    0.018   11435.0    2988.0    1.0
participant_intercept[3]   -0.741  0.977  -2.535    1.102      0.011    0.013    8387.0    2807.0    1.0
participant_intercept[4]   -0.437  0.966  -2.330    1.337      0.010    0.015    9120.0    2976.0    1.0
participant_intercept[5]   -2.082  0.972  -3.903   -0.256      0.009    0.008   10363.0    2993.0    1.0
participant_intercept[6]   -0.679  1.005  -2.621    1.118      0.011    0.015    8901.0    2704.0    1.0
participant_intercept[7]    0.397  1.001  -1.482    2.259      0.011    0.017    8807.0    2412.0    1.0
participant_intercept[8]   -0.868  0.965  -2.620    1.028      0.010    0.014    8758.0    2299.0    1.0
participant_intercept[9]    2.049  0.980   0.091    3.819      0.009    0.008   10792.0    2811.0    1.0
participant_intercept[10]  -0.424  0.987  -2.279    1.406      0.010    0.015   10216.0    2797.0    1.0
participant_intercept[11]   0.751  0.993  -1.185    2.564      0.010    0.013   10507.0    3141.0    1.0
participant_intercept[12]   0.556  0.967  -1.135    2.467      0.010    0.015    9797.0    2754.0    1.0
participant_intercept[13]   0.879  1.009  -1.057    2.680      0.010    0.012   10859.0    3109.0    1.0
sigma                      31.722  0.866  30.199   33.397      0.009    0.006    9753.0    3054.0    1.0

==================================================

Running model with typing_time prior: N(50, 1)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.847  0.435   0.033    1.661      0.005    0.004    8133.0    3278.0    1.0
finger2                     0.113  0.436  -0.755    0.913      0.005    0.007    8344.0    3154.0    1.0
finger3                     0.164  0.440  -0.613    1.027      0.005    0.007    8142.0    3106.0    1.0
finger4                     0.872  0.433   0.067    1.696      0.005    0.004    9112.0    3247.0    1.0
typing_time                58.987  1.340  56.595   61.516      0.015    0.011    7937.0    3748.0    1.0
participant_intercept[0]    2.586  0.965   0.801    4.435      0.010    0.008    9304.0    3030.0    1.0
participant_intercept[1]   -1.937  0.978  -3.790   -0.139      0.011    0.009    8212.0    2787.0    1.0
participant_intercept[2]   -0.058  0.955  -1.802    1.780      0.010    0.017    9514.0    2864.0    1.0
participant_intercept[3]   -0.738  0.985  -2.468    1.189      0.010    0.013   10040.0    3061.0    1.0
participant_intercept[4]   -0.440  0.968  -2.355    1.286      0.010    0.015    9333.0    2766.0    1.0
participant_intercept[5]   -2.086  0.997  -4.065   -0.229      0.010    0.009    9040.0    2678.0    1.0
participant_intercept[6]   -0.656  0.986  -2.547    1.174      0.011    0.013    8614.0    2928.0    1.0
participant_intercept[7]    0.374  0.979  -1.544    2.097      0.011    0.016    8322.0    2901.0    1.0
participant_intercept[8]   -0.872  0.969  -2.739    0.895      0.011    0.013    8395.0    2740.0    1.0
participant_intercept[9]    2.034  0.984   0.102    3.800      0.010    0.009    9059.0    3235.0    1.0
participant_intercept[10]  -0.423  1.008  -2.351    1.408      0.010    0.016   10625.0    3053.0    1.0
participant_intercept[11]   0.765  1.004  -1.109    2.626      0.010    0.013   10802.0    3055.0    1.0
participant_intercept[12]   0.565  1.009  -1.270    2.423      0.012    0.015    7454.0    2856.0    1.0
participant_intercept[13]   0.888  0.969  -0.974    2.601      0.010    0.012   10233.0    3071.0    1.0
sigma                      31.718  0.862  30.123   33.346      0.009    0.006    9642.0    3218.0    1.0

==================================================

Running model with typing_time prior: N(50, 10)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.852  0.445   0.053    1.727      0.005    0.004    8214.0    3105.0    1.0
finger2                     0.105  0.446  -0.757    0.925      0.005    0.007    7397.0    2809.0    1.0
finger3                     0.171  0.444  -0.637    1.020      0.005    0.007    7962.0    2774.0    1.0
finger4                     0.864  0.437   0.015    1.685      0.005    0.004    7812.0    3121.0    1.0
typing_time                58.978  1.332  56.371   61.337      0.016    0.011    7100.0    3428.0    1.0
participant_intercept[0]    2.588  0.954   0.778    4.376      0.011    0.008    8210.0    3071.0    1.0
participant_intercept[1]   -1.930  0.980  -3.821   -0.199      0.011    0.009    8136.0    2575.0    1.0
participant_intercept[2]   -0.067  1.003  -1.952    1.733      0.011    0.017    8255.0    3008.0    1.0
participant_intercept[3]   -0.701  0.998  -2.685    1.061      0.011    0.015    7952.0    2652.0    1.0
participant_intercept[4]   -0.462  0.945  -2.284    1.313      0.010    0.013    9060.0    3131.0    1.0
participant_intercept[5]   -2.078  0.982  -3.919   -0.236      0.011    0.009    8099.0    2962.0    1.0
participant_intercept[6]   -0.685  0.990  -2.511    1.192      0.011    0.013    8828.0    2905.0    1.0
participant_intercept[7]    0.384  1.002  -1.556    2.167      0.010    0.017   10439.0    3010.0    1.0
participant_intercept[8]   -0.858  0.987  -2.674    0.972      0.011    0.012    8836.0    3125.0    1.0
participant_intercept[9]    2.025  0.965   0.221    3.844      0.010    0.009    9670.0    3181.0    1.0
participant_intercept[10]  -0.404  0.991  -2.225    1.521      0.011    0.016    7875.0    2524.0    1.0
participant_intercept[11]   0.772  0.989  -1.062    2.644      0.011    0.012    8400.0    3250.0    1.0
participant_intercept[12]   0.553  0.997  -1.291    2.443      0.010    0.014    9180.0    3245.0    1.0
participant_intercept[13]   0.875  0.958  -0.831    2.710      0.011    0.012    7562.0    3063.0    1.0
sigma                      31.721  0.852  30.126   33.324      0.010    0.007    7602.0    3327.0    1.0

==================================================

Running model with typing_time prior: N(50, 100)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.834  0.450  -0.041    1.651      0.005    0.004    8742.0    3159.0    1.0
finger2                     0.106  0.437  -0.730    0.900      0.005    0.007    8771.0    3082.0    1.0
finger3                     0.159  0.450  -0.679    0.982      0.005    0.007    8874.0    3485.0    1.0
finger4                     0.871  0.446  -0.011    1.675      0.005    0.004    8044.0    3075.0    1.0
typing_time                59.009  1.369  56.469   61.547      0.016    0.012    6883.0    3371.0    1.0
participant_intercept[0]    2.597  0.967   0.661    4.362      0.011    0.008    7964.0    2646.0    1.0
participant_intercept[1]   -1.932  0.982  -3.733   -0.067      0.010    0.008   10459.0    3324.0    1.0
participant_intercept[2]   -0.053  0.981  -1.915    1.805      0.010    0.018    9525.0    2744.0    1.0
participant_intercept[3]   -0.728  0.991  -2.557    1.138      0.010    0.015    9392.0    2874.0    1.0
participant_intercept[4]   -0.443  0.977  -2.293    1.325      0.009    0.014   11808.0    3377.0    1.0
participant_intercept[5]   -2.086  0.974  -4.031   -0.401      0.011    0.010    7352.0    2702.0    1.0
participant_intercept[6]   -0.655  1.004  -2.491    1.229      0.011    0.014    8044.0    2711.0    1.0
participant_intercept[7]    0.382  0.978  -1.408    2.258      0.010    0.017    9498.0    2761.0    1.0
participant_intercept[8]   -0.862  1.031  -2.824    1.044      0.010    0.013   10462.0    2783.0    1.0
participant_intercept[9]    2.023  0.974   0.239    3.834      0.010    0.008   10080.0    2857.0    1.0
participant_intercept[10]  -0.419  0.951  -2.168    1.317      0.010    0.015    9233.0    3037.0    1.0
participant_intercept[11]   0.763  1.011  -1.194    2.670      0.009    0.014   11599.0    2464.0    1.0
participant_intercept[12]   0.562  0.992  -1.229    2.475      0.011    0.016    8168.0    2546.0    1.0
participant_intercept[13]   0.891  0.965  -0.936    2.704      0.011    0.012    7800.0    2852.0    1.0
sigma                      31.716  0.834  30.061   33.219      0.009    0.007    7727.0    3132.0    1.0

==================================================

Running model with typing_time prior: N(100, 1)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.847  0.441   0.020    1.672      0.005    0.005    8056.0    3302.0   1.00
finger2                     0.116  0.447  -0.747    0.922      0.005    0.009    9913.0    2545.0   1.00
finger3                     0.170  0.438  -0.615    1.016      0.005    0.007    8854.0    3295.0   1.00
finger4                     0.866  0.437   0.088    1.708      0.005    0.004    8266.0    3512.0   1.00
typing_time                59.007  1.321  56.643   61.617      0.015    0.011    7719.0    3420.0   1.00
participant_intercept[0]    2.594  1.017   0.583    4.418      0.010    0.008   10216.0    3298.0   1.00
participant_intercept[1]   -1.938  0.986  -3.762   -0.009      0.011    0.009    8001.0    2809.0   1.00
participant_intercept[2]   -0.054  0.968  -1.866    1.719      0.010    0.016    9660.0    3092.0   1.00
participant_intercept[3]   -0.713  0.977  -2.454    1.225      0.011    0.013    7993.0    2815.0   1.00
participant_intercept[4]   -0.443  0.989  -2.441    1.292      0.011    0.016    8573.0    2587.0   1.00
participant_intercept[5]   -2.090  0.987  -3.938   -0.199      0.010    0.009    9705.0    3050.0   1.00
participant_intercept[6]   -0.657  0.960  -2.418    1.176      0.010    0.013    8711.0    3289.0   1.00
participant_intercept[7]    0.378  0.999  -1.470    2.292      0.010    0.017    9381.0    2646.0   1.01
participant_intercept[8]   -0.864  0.981  -2.761    0.871      0.011    0.012    8566.0    3245.0   1.00
participant_intercept[9]    2.025  0.970   0.274    3.894      0.010    0.009    9554.0    2753.0   1.00
participant_intercept[10]  -0.417  0.982  -2.208    1.475      0.010    0.016    9415.0    2558.0   1.00
participant_intercept[11]   0.757  0.992  -1.149    2.541      0.010    0.013    9281.0    2912.0   1.00
participant_intercept[12]   0.548  0.991  -1.218    2.461      0.011    0.015    8355.0    2763.0   1.00
participant_intercept[13]   0.865  0.993  -1.124    2.675      0.010    0.013    8999.0    2868.0   1.00
sigma                      31.720  0.892  30.033   33.391      0.011    0.007    7245.0    3305.0   1.00

==================================================

Running model with typing_time prior: N(100, 10)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.856  0.444   0.031    1.684      0.005    0.004    7822.0    3242.0    1.0
finger2                     0.114  0.448  -0.725    0.943      0.005    0.007    8485.0    3077.0    1.0
finger3                     0.167  0.443  -0.708    0.964      0.005    0.008    9012.0    2950.0    1.0
finger4                     0.872  0.441   0.044    1.705      0.005    0.004    7690.0    3209.0    1.0
typing_time                58.982  1.341  56.312   61.329      0.016    0.011    7114.0    3195.0    1.0
participant_intercept[0]    2.602  0.974   0.695    4.391      0.010    0.008    9696.0    2691.0    1.0
participant_intercept[1]   -1.943  0.980  -3.735   -0.051      0.011    0.009    8094.0    2718.0    1.0
participant_intercept[2]   -0.076  0.991  -1.843    1.841      0.012    0.017    7376.0    2746.0    1.0
participant_intercept[3]   -0.730  0.955  -2.495    1.081      0.010    0.013    9164.0    2988.0    1.0
participant_intercept[4]   -0.460  0.963  -2.335    1.259      0.011    0.014    7823.0    2991.0    1.0
participant_intercept[5]   -2.089  0.975  -4.010   -0.311      0.011    0.009    8385.0    2960.0    1.0
participant_intercept[6]   -0.651  0.989  -2.432    1.232      0.010    0.014    9977.0    2746.0    1.0
participant_intercept[7]    0.382  0.973  -1.434    2.193      0.010    0.015    8812.0    2930.0    1.0
participant_intercept[8]   -0.856  0.969  -2.691    0.959      0.010    0.012    9971.0    2939.0    1.0
participant_intercept[9]    2.032  0.960   0.236    3.778      0.011    0.009    8179.0    2957.0    1.0
participant_intercept[10]  -0.429  0.996  -2.310    1.384      0.011    0.016    7492.0    2751.0    1.0
participant_intercept[11]   0.755  0.983  -1.051    2.587      0.011    0.012    8179.0    2850.0    1.0
participant_intercept[12]   0.556  1.013  -1.335    2.477      0.011    0.015    9025.0    2730.0    1.0
participant_intercept[13]   0.883  0.993  -1.039    2.668      0.011    0.013    8797.0    3071.0    1.0
sigma                      31.709  0.880  30.161   33.456      0.009    0.007    8620.0    3041.0    1.0

==================================================

Running model with typing_time prior: N(100, 100)

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, typing_time, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 3 seconds.
                             mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
finger1                     0.853  0.437   0.035    1.649      0.005    0.004    9356.0    3060.0    1.0
finger2                     0.112  0.448  -0.731    0.923      0.005    0.007    7865.0    2926.0    1.0
finger3                     0.158  0.427  -0.602    0.977      0.005    0.007    8231.0    2688.0    1.0
finger4                     0.868  0.439   0.044    1.685      0.005    0.004    7352.0    3421.0    1.0
typing_time                59.009  1.354  56.646   61.714      0.016    0.011    7162.0    3397.0    1.0
participant_intercept[0]    2.584  0.984   0.840    4.493      0.010    0.008    9226.0    3173.0    1.0
participant_intercept[1]   -1.942  0.970  -3.737   -0.119      0.010    0.009    8589.0    3131.0    1.0
participant_intercept[2]   -0.067  1.007  -1.932    1.860      0.010    0.018   10339.0    2910.0    1.0
participant_intercept[3]   -0.717  0.996  -2.552    1.203      0.011    0.014    8540.0    2787.0    1.0
participant_intercept[4]   -0.439  0.957  -2.109    1.521      0.010    0.015    9159.0    3140.0    1.0
participant_intercept[5]   -2.088  0.962  -4.073   -0.437      0.011    0.009    7488.0    3047.0    1.0
participant_intercept[6]   -0.687  0.996  -2.579    1.168      0.011    0.014    7582.0    2924.0    1.0
participant_intercept[7]    0.401  0.952  -1.446    2.121      0.010    0.016    9255.0    3204.0    1.0
participant_intercept[8]   -0.858  0.951  -2.596    0.975      0.010    0.012    8752.0    2975.0    1.0
participant_intercept[9]    2.033  0.969   0.312    3.918      0.011    0.009    7822.0    2959.0    1.0
participant_intercept[10]  -0.412  0.970  -2.337    1.318      0.011    0.016    7623.0    2679.0    1.0
participant_intercept[11]   0.763  0.981  -1.046    2.702      0.011    0.013    8710.0    3120.0    1.0
participant_intercept[12]   0.547  0.997  -1.384    2.324      0.011    0.014    7592.0    3249.0    1.0
participant_intercept[13]   0.889  1.005  -0.997    2.795      0.011    0.012    8579.0    3003.0    1.0
sigma                      31.697  0.878  30.160   33.474      0.010    0.007    8469.0    3584.0    1.0

==================================================


 ---- Run Bayesian cross-validation ---- 


 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001418

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001418

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.07671320486001418

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.0767132048600141

 ---- Train Bayesian GLMM ---- 

Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [finger1, finger2, finger3, finger4, participant_intercept, sigma]
Sampling 4 chains, 0 divergences ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 / 0:00:02
Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 2 seconds.
All parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Feature-based parameters: ['finger1', 'finger2', 'finger3', 'finger4']
Manual parameters: []
Cross-validation fold score: 0.0767132048600141
Mean CV Score: 0.07671320486001414


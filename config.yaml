# Data settings
data:
  #file: "data/input/processed_output_all4studies_303of406participants_0inconsistencies_with_no_improbable/tables/processed_data/processed_bigram_data.csv"
  #file: "data/input/processed_output_all4studies_303of406participants_with_no_improbable/tables/processed_data/processed_bigram_data.csv"
  #file: "data/input/processed_output_all4studies_406participants_0inconsistencies/tables/processed_data/processed_bigram_data.csv"
  file: "data/input/processed_output_all4studies_406participants/tables/processed_data/processed_bigram_data.csv"
  splits:
    test_ratio: 0.2
    random_seed: 42
  
  # Keyboard layout
  layout:
    chars: ['q', 'w', 'e', 'r', 't', 'a', 's', 'd', 'f', 'g', 'z', 'x', 'c', 'v', 'b']

# Feature settings
features:
  base_features:
    - typing_time
    - same_finger
    - sum_finger_values
    - adj_finger_diff_row
    - rows_apart
    - angle_apart
    - outward_roll
    - middle_column
    - sum_engram_position_values
    - sum_row_position_values
  interactions_file: "data/filtered_feature_interactions.txt"

# Feature evaluation settings
feature_evaluation:
  enabled: true
  thresholds:
    importance: 0.05
    stability: 0.7
    correlation: 0.7
  analysis:
    check_transitivity: true
    analyze_features: true
    find_sparse_regions: true
    evaluate_features: true
  validation:
    perform_stability_check: true
    min_training_samples: 1000
    min_validation_samples: 200
    outlier_detection: true
    outlier_threshold: 3.0
  reporting:
    save_raw_metrics: true
  output_dir: "output/feature_evaluation"

recommendations:
  n_recommendations: 20
  uncertainty_threshold: 0.8  # For high uncertainty regions
  interaction_strength_threshold: 0.3  # For feature interactions
  transitivity_chain_length: 3  # For transitivity testing

model:
  train: false
  chains: 8
  target_accept: 0.85
  n_samples: 10000
  cross_validation:
    n_splits: 5
    n_repetitions: 1
    random_seed: 42

# Logging settings
logging:
  # set level to "DEBUG" or "INFO" at the top of main.py
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "output/logs/pipeline.log"

# Output paths
paths:
  base: "output"
  analysis: "output/analysis"
